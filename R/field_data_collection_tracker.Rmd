---
title: "Diagnostic of informality tracker"
author: ""
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = paste0(dirname(inputFile), '/diagnostic_of_informality_tracker_', format(Sys.Date(), '%Y_%m_%d'),'.html')) })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

# read packages
library(tidyverse)
library(glue)
library(htmlwidgets)

df_samples <- readr::read_csv("../inputs/diagnostic_survey_samples_definition.csv")

df_for_colnames <- df_samples %>% 
  select(location) %>% 
  unique()

df_samples_required <- df_samples %>% 
  select(site_id, sample_size)

# tool
loc_tool <- "../inputs/Diagnostic_of_informality_Tool.xlsx"
df_survey <- readxl::read_excel(loc_tool, sheet = "survey")
df_choices <- readxl::read_excel(loc_tool, sheet = "choices")

# data
df_tool_data <- readxl::read_excel("../inputs/Diagnostic_of_informality_Data.xlsx") %>%
  mutate(uuid = `_uuid`,
         start = as_datetime(start),
         end = as_datetime(end),
         start_date = as_date(start),
         location = case_when(interview_loc_level %in% c("municipality") ~ municipality,
                              interview_loc_level %in% c("town_council") ~ town_council,
                              interview_loc_level %in% c("village_council") ~ village_council,
                              interview_loc_level %in% c("settlement") ~ settlement),
         int.site_formality = case_when(poi_category %in% c("1")|interview_site_category %in% c("1") ~ "formal",
                                        poi_category %in% c("2")|interview_site_category %in% c("2") ~ "informal",
                                        poi_category %in% c("3")|interview_site_category %in% c("3") ~ "household",
                                        ),
         site_id = paste0(location, "_", int.site_formality)) #%>% 
  # filter(start_date >= as_date("2024-10-07")) 

# days that contain data
df_days_for_data_collection <- df_tool_data %>% select(start_date) %>% unique() %>% arrange(start_date) %>% pull()

df_data_support_cl_log <- df_tool_data %>% 
  select(uuid, site_id)


# cleaning log handling
df_cl_log <- readxl::read_excel("../inputs/combined_checks_nam_diagnostic.xlsx", sheet = "cleaning_log") %>% 
  left_join(df_data_support_cl_log, by = "uuid")

# change_response logs that affect stats in the data collection progress ref
cl_log_change_response <- df_cl_log %>%
  mutate(question = str_replace(string = question,
                                pattern = "_\\d+$",
                                replacement = paste0("/", str_extract(string = question, pattern = "\\d+$")))) %>%
  filter(change_type == "change_response", !is.na(reviewed), !question %in% c("_index"), !uuid %in% c("all"),
         !(is.na(new_value)|new_value %in% c("NA")),
         !str_detect(string = question, "\\/")
  ) %>%
  select(uuid, question, new_value)

# updated tool data ref
df_updated_tool_data <- df_tool_data

# get uuids from cleaning log
uuids_chg_response <- cl_log_change_response %>% pull(uuid) %>% unique()

for (current_uuid in uuids_chg_response) {
    current_uuid_data <- cl_log_change_response %>%
        filter(uuid == current_uuid) 
    print(current_uuid_data)
    # process current updates
    df_current_updated <- df_updated_tool_data %>%
        rows_update(y = current_uuid_data, by = "uuid")

    # update the parent dataset with current updates
    df_updated_tool_data <- df_current_updated
}

# seperate site and poi data

df_sites_data <- df_updated_tool_data %>% 
  filter(location_type %in% c("interview_site"))

df_pois_data <- df_updated_tool_data %>% 
  filter(location_type %in% c("poi"))

# enumerator performance data
df_enum_performance <- df_sites_data %>% 
  mutate(int.survey_time_interval = lubridate::time_length(end - start, unit = "min"),
         int.survey_time_interval = ceiling(int.survey_time_interval))

# surveys for deletion
df_cl_deletion <- df_cl_log %>% 
  filter(change_type %in% "remove_survey", reviewed == 1) %>%
  mutate(site_id = site_id.y) %>% 
  distinct(site_id, uuid)

# functions for changing some options in the table
dt_set_options<- function(x){
  DT::datatable(x,
                options = list(
                  autoWidth=F,
                  dom= 't',
                  list(list(width = '20%', targets = list(1,2,3,4,5)))
                )
  )
}


dt_options_fewcols <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  pageLength = 50,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
                )
  )
}

```

## Summary on the surveys done

>The average survey time for the data is: **`r round(mean(df_enum_performance$int.survey_time_interval), 0)`** Minutes

>Total surveys: **`r nrow(df_updated_tool_data)`**,\
Surveys for deletion: **`r nrow(df_cl_deletion)`**,\
Last date of data collection: **`r df_days_for_data_collection[length(df_days_for_data_collection)]`**.

### Summary on the surveys per location

```{r, echo = FALSE}
df_samp_per_location <- df_samples_required %>% 
  select(site_id, samples = sample_size)

df_cl_surveys_for_deletion <- df_cl_log %>% 
  filter(change_type == "remove_survey", reviewed == 1) %>% 
  rename(location = location.y) %>% 
  group_by(location) %>% 
  distinct(uuid) %>%
  summarise(surveys_for_deletion = n())


df_updated_tool_data %>% 
  group_by(site_id) %>% 
  summarise(surveys_completed = n()) %>% 
  arrange(location) %>% 
  right_join(df_samp_per_location, by = "site_id") %>% 
  left_join(df_cl_surveys_for_deletion, by = "site_id") %>% 
  mutate(surveys_completed = ifelse(is.na(surveys_completed), 0, surveys_completed),
         surveys_for_deletion = ifelse(is.na(surveys_for_deletion), 0, surveys_for_deletion),
         int.surveys_and_deletion = surveys_completed - surveys_for_deletion,
         remaining_surveys = samples - int.surveys_and_deletion
  ) %>% 
  left_join(df_for_colnames, by = "site_id") %>% 
  select(-c(int.surveys_and_deletion)) %>% 
  dt_options_fewcols()

```

### Daily enumerator performance

```{r, echo = FALSE}

df_enum_performance %>%
  group_by(location, start_date, enum) %>%
  summarise(number_of_interviews_done = n(), `average_survey_time(minutes)` =    round(mean(int.survey_time_interval, na.rm = TRUE), 0)) %>%
  dt_options_fewcols()
```


### Number of issues by enumerator

```{r, echo = FALSE}
df_cl_log %>%
  rename(location = location.y) %>%
  group_by(location, enum) %>%
  summarise(number_of_issues_by_enum = n()) %>%
  dt_options_fewcols()
```


### Enumerators with surveys for deletion

```{r, echo = FALSE}
df_cl_log %>%
  filter(change_type == "remove_survey", reviewed == 1) %>%
  rename(location = location.y) %>%
  distinct(location, uuid, enum) %>%
  group_by(location, enum) %>%
  summarise(number_of_surveys_for_deletion_by_enumerator = n()) %>%
  dt_options_fewcols()
```
